{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The above code was for help, now I know what's going on. \n",
    "\n",
    "### Let's do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T20:19:50.472795Z",
     "iopub.status.busy": "2025-11-28T20:19:50.472545Z",
     "iopub.status.idle": "2025-11-28T20:19:54.476364Z",
     "shell.execute_reply": "2025-11-28T20:19:54.475737Z",
     "shell.execute_reply.started": "2025-11-28T20:19:50.472776Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0. Imports & global settings\n",
    "# ============================================================\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "MOD = 97  # modulus\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    \"figure.dpi\": 300,               # display DPI (useful for interactive), but saving uses savefig's dpi\n",
    "    \"savefig.dpi\": 300,              # default saved raster DPI\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times New Roman\", \"Times\", \"DejaVu Serif\"],\n",
    "    \"mathtext.fontset\": \"cm\",        # or \"stix\" for Times-like math\n",
    "    \"axes.titlesize\": 11,\n",
    "    \"axes.labelsize\": 10,\n",
    "    \"xtick.labelsize\": 8,\n",
    "    \"ytick.labelsize\": 8,\n",
    "    \"legend.fontsize\": 8,\n",
    "    \"lines.linewidth\": 1.0,\n",
    "    \"lines.markersize\": 5,\n",
    "    \"axes.linewidth\": 0.8,\n",
    "    \"axes.grid\": False,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T20:19:54.478120Z",
     "iopub.status.busy": "2025-11-28T20:19:54.477803Z",
     "iopub.status.idle": "2025-11-28T20:19:54.506747Z",
     "shell.execute_reply": "2025-11-28T20:19:54.506129Z",
     "shell.execute_reply.started": "2025-11-28T20:19:54.478101Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes:\n",
      "Addition: 9409\n",
      "Multiplication: 9409\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1. Dataset: modular addition / multiplication on Z_97\n",
    "# ============================================================\n",
    "\n",
    "class ModArithDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Generates all pairs (a, b) in {0..MOD-1}^2\n",
    "    with label f(a,b) = a [+ or *] b (mod MOD).\n",
    "    \"\"\"\n",
    "    def __init__(self, op=\"add\"):\n",
    "        assert op in [\"add\", \"mul\"]\n",
    "        self.op = op\n",
    "\n",
    "        xs = []\n",
    "        ys = []\n",
    "        for a in range(MOD):\n",
    "            for b in range(MOD):\n",
    "                xs.append((a, b))\n",
    "                if op == \"add\":\n",
    "                    ys.append((a + b) % MOD)\n",
    "                else:\n",
    "                    ys.append((a * b) % MOD)\n",
    "\n",
    "        self.x = torch.tensor(xs, dtype=torch.long)  # [N, 2]\n",
    "        self.y = torch.tensor(ys, dtype=torch.long)  # [N]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "print(\"Dataset sizes:\")\n",
    "print(\"Addition:\", len(ModArithDataset(\"add\")))\n",
    "print(\"Multiplication:\", len(ModArithDataset(\"mul\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T20:19:54.507982Z",
     "iopub.status.busy": "2025-11-28T20:19:54.507570Z",
     "iopub.status.idle": "2025-11-28T20:19:54.514915Z",
     "shell.execute_reply": "2025-11-28T20:19:54.514278Z",
     "shell.execute_reply.started": "2025-11-28T20:19:54.507958Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. Models: BilinearMLP and ReluMLP\n",
    "# ============================================================\n",
    "\n",
    "class BilinearMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Two-input bilinear MLP:\n",
    "      e_a = Emb_a[a], e_b = Emb_b[b]\n",
    "      u = W1(e_a), v = W2(e_b)\n",
    "      h = u * v (Hadamard)\n",
    "      logits = W_out(h)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_tokens=MOD, d=32, m=64):\n",
    "        super().__init__()\n",
    "        self.emb_a = nn.Embedding(num_tokens, d)\n",
    "        self.emb_b = nn.Embedding(num_tokens, d)\n",
    "        self.W1 = nn.Linear(d, m, bias=False)\n",
    "        self.W2 = nn.Linear(d, m, bias=False)\n",
    "        self.out = nn.Linear(m, num_tokens, bias=False)\n",
    "\n",
    "    def forward(self, a, b):\n",
    "        # a, b: [B] long\n",
    "        e_a = self.emb_a(a)   # [B, d]\n",
    "        e_b = self.emb_b(b)   # [B, d]\n",
    "        u = self.W1(e_a)      # [B, m]\n",
    "        v = self.W2(e_b)      # [B, m]\n",
    "        h = u * v             # bilinear interaction\n",
    "        logits = self.out(h)  # [B, MOD]\n",
    "        return logits\n",
    "\n",
    "\n",
    "class ReluMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Baseline ReLU MLP:\n",
    "      e_a, e_b embeddings\n",
    "      x = [e_a; e_b]\n",
    "      h = ReLU(W(x))\n",
    "      logits = W_out(h)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_tokens=MOD, d=32, m=64):\n",
    "        super().__init__()\n",
    "        self.emb_a = nn.Embedding(num_tokens, d)\n",
    "        self.emb_b = nn.Embedding(num_tokens, d)\n",
    "        self.fc1 = nn.Linear(2 * d, m)\n",
    "        self.out = nn.Linear(m, num_tokens)\n",
    "\n",
    "    def forward(self, a, b):\n",
    "        e_a = self.emb_a(a)\n",
    "        e_b = self.emb_b(b)\n",
    "        x = torch.cat([e_a, e_b], dim=-1)  # [B, 2d]\n",
    "        h = F.relu(self.fc1(x))            # [B, m]\n",
    "        logits = self.out(h)               # [B, MOD]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T20:19:54.515823Z",
     "iopub.status.busy": "2025-11-28T20:19:54.515598Z",
     "iopub.status.idle": "2025-11-28T20:19:54.533302Z",
     "shell.execute_reply": "2025-11-28T20:19:54.532543Z",
     "shell.execute_reply.started": "2025-11-28T20:19:54.515800Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. Generic training loop\n",
    "# ============================================================\n",
    "\n",
    "def train_model(model, dataset, epochs=200, batch_size=256, lr=1e-3, verbose_every=20):\n",
    "    model = model.to(device)\n",
    "    N = len(dataset)\n",
    "    n_train = int(0.8 * N)\n",
    "    n_val = N - n_train\n",
    "    train_ds, val_ds = random_split(dataset, [n_train, n_val])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for (x, y) in train_loader:\n",
    "            a, b = x[:, 0].to(device), x[:, 1].to(device)\n",
    "            y = y.to(device)\n",
    "            logits = model(a, b)\n",
    "            loss = criterion(logits, y)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * y.size(0)\n",
    "        train_loss = total_loss / n_train\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for (x, y) in val_loader:\n",
    "                a, b = x[:, 0].to(device), x[:, 1].to(device)\n",
    "                y = y.to(device)\n",
    "                logits = model(a, b)\n",
    "                pred = logits.argmax(dim=1)\n",
    "                correct += (pred == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        val_acc = correct / total\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        if (epoch % verbose_every) == 0 or epoch == epochs - 1:\n",
    "            print(f\"[epoch {epoch:3d}] loss={train_loss:.4f}  val_acc={val_acc:.4f}\")\n",
    "            if(val_acc>0.999):\n",
    "                print(\"Early Stopping Triggered!\")\n",
    "                break\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T20:19:54.534075Z",
     "iopub.status.busy": "2025-11-28T20:19:54.533830Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. Train models for ADDITION\n",
    "# ============================================================\n",
    "\n",
    "add_dataset = ModArithDataset(op=\"add\")\n",
    "\n",
    "bilinear_add = BilinearMLP(d=32, m=64)\n",
    "relu_add     = ReluMLP(d=32, m=64)\n",
    "\n",
    "print(\"Training Bilinear MLP on addition...\")\n",
    "bilinear_add, hist_b_add = train_model(bilinear_add, add_dataset, epochs=2000)\n",
    "\n",
    "print(\"\\nTraining ReLU MLP on addition...\")\n",
    "relu_add, hist_r_add = train_model(relu_add, add_dataset, epochs=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. Train models for MULTIPLICATION\n",
    "# ============================================================\n",
    "\n",
    "mul_dataset = ModArithDataset(op=\"mul\")\n",
    "\n",
    "bilinear_mul = BilinearMLP(d=32, m=64)\n",
    "relu_mul     = ReluMLP(d=32, m=64)\n",
    "\n",
    "print(\"Training Bilinear MLP on multiplication...\")\n",
    "bilinear_mul, hist_b_mul = train_model(bilinear_mul, mul_dataset, epochs=2000)\n",
    "\n",
    "print(\"\\nTraining ReLU MLP on multiplication...\")\n",
    "relu_mul, hist_r_mul = train_model(relu_mul, mul_dataset, epochs=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aditya\\AppData\\Local\\Temp\\ipykernel_25696\\2477891122.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  bilinear_add = torch.load('bilinear_add.pth')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# torch.save(bilinear_add, \"/kaggle/working/bilinear_add.pth\")\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# torch.save(bilinear_mul, \"/kaggle/working/bilinear_mul.pth\")\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# torch.save(relu_mul, \"/kaggle/working/relu_mul.pth\")\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# torch.save(relu_add, \"/kaggle/working/relu_add.pth\")\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m bilinear_add \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbilinear_add.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m bilinear_mul \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear_mul.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m relu_add \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu_add.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\serialization.py:1360\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1358\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1359\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1360\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1364\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1368\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\serialization.py:1848\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[0;32m   1847\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[1;32m-> 1848\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1849\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1851\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\serialization.py:1812\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1810\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1811\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1812\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1814\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\serialization.py:1784\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1779\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1784\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1785\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1786\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1787\u001b[0m )\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1790\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\serialization.py:601\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;124;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;124;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 601\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    603\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\serialization.py:539\u001b[0m, in \u001b[0;36m_deserialize\u001b[1;34m(backend_name, obj, location)\u001b[0m\n\u001b[0;32m    537\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_privateuse1_backend_name()\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[1;32m--> 539\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\Aditya\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\serialization.py:508\u001b[0m, in \u001b[0;36m_validate_device\u001b[1;34m(location, backend_name)\u001b[0m\n\u001b[0;32m    506\u001b[0m     device_index \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_available\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m--> 508\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    509\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.is_available() is False. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    511\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m     )\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice_count\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    516\u001b[0m     device_count \u001b[38;5;241m=\u001b[39m device_module\u001b[38;5;241m.\u001b[39mdevice_count()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "# torch.save(bilinear_add, \"/kaggle/working/bilinear_add.pth\")\n",
    "# torch.save(bilinear_mul, \"/kaggle/working/bilinear_mul.pth\")\n",
    "# torch.save(relu_mul, \"/kaggle/working/relu_mul.pth\")\n",
    "# torch.save(relu_add, \"/kaggle/working/relu_add.pth\")\n",
    "\n",
    "bilinear_add = torch.load('bilinear_add.pth')\n",
    "bilinear_mul = torch.load('bilinear_mul.pth')\n",
    "relu_add = torch.load('relu_add.pth')\n",
    "relu_mul = torch.load('relu_mul.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6. Utility: build full logits grid for all (a,b)\n",
    "# ============================================================\n",
    "\n",
    "def full_logits_grid(model):\n",
    "    \"\"\"\n",
    "    Return logits[a,b,k] for all a,b ∈ {0..MOD-1}.\n",
    "    model is already trained.\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        a_idx = torch.arange(MOD, device=device)\n",
    "        b_idx = torch.arange(MOD, device=device)\n",
    "        A, B = torch.meshgrid(a_idx, b_idx, indexing=\"ij\")  # [MOD,MOD]\n",
    "        A_flat = A.reshape(-1)\n",
    "        B_flat = B.reshape(-1)\n",
    "        logits = model(A_flat, B_flat)  # [MOD*MOD, MOD]\n",
    "        logits = logits.reshape(MOD, MOD, MOD)  # [a,b,k]\n",
    "    return logits.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7. Extract Mk from Bilinear weights (weight-level)\n",
    "# ============================================================\n",
    "\n",
    "def extract_Mk_bilinear_from_weights(model: BilinearMLP):\n",
    "    \"\"\"\n",
    "    Analytic extraction of M_k[a,b] from bilinear weights.\n",
    "    Returns Mk: numpy array of shape [MOD, MOD, MOD] where Mk[a,b,k].\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    with torch.no_grad():\n",
    "        # Embeddings: [MOD, d]\n",
    "        E_a = model.emb_a.weight.data.clone().to(device)\n",
    "        E_b = model.emb_b.weight.data.clone().to(device)\n",
    "\n",
    "        # Linear weights: nn.Linear stores weight [out_dim, in_dim]\n",
    "        # We want W1: [d,m], W2: [d,m], out: [m,MOD]\n",
    "        W1 = model.W1.weight.data.clone().to(device).T   # [d, m]\n",
    "        W2 = model.W2.weight.data.clone().to(device).T   # [d, m]\n",
    "        O  = model.out.weight.data.clone().to(device).T  # [m, MOD]\n",
    "\n",
    "        # U[a,j] = e_a W1[:,j]\n",
    "        U = E_a @ W1      # [MOD, m]\n",
    "        V = E_b @ W2      # [MOD, m]\n",
    "\n",
    "        U_np = U.cpu().numpy()   # [MOD, m]\n",
    "        V_np = V.cpu().numpy()   # [MOD, m]\n",
    "        O_np = O.cpu().numpy()   # [m, MOD]\n",
    "\n",
    "    # hidden_pair[a,b,j] = U[a,j] * V[b,j]\n",
    "    A = U_np[:, None, :]    # [MOD, 1, m]\n",
    "    B = V_np[None, :, :]    # [1, MOD, m]\n",
    "    hidden_pair = A * B     # [MOD, MOD, m]\n",
    "\n",
    "    # Contract hidden dimension with out weights:\n",
    "    # Mk[a,b,k] = sum_j hidden_pair[a,b,j] * O[j,k]\n",
    "    Mk = np.einsum(\"abm,mk->abk\", hidden_pair, O_np)  # [MOD, MOD, MOD]\n",
    "    return Mk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 8. Alternate: Mk directly from logits for ANY model\n",
    "# ============================================================\n",
    "\n",
    "def extract_Mk_from_logits(model):\n",
    "    \"\"\"\n",
    "    For any model, simply interpret the logits grid as M_k[a,b].\n",
    "    i.e., M_k[a,b] = logits_k(a,b).\n",
    "    This is exact for discrete domain, though not weight-analytic.\n",
    "    \"\"\"\n",
    "    logits = full_logits_grid(model)  # [a,b,k]\n",
    "    return logits  # same shape [MOD,MOD,MOD]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Mk_add_bilin_w  = extract_Mk_bilinear_from_weights(bilinear_add)\n",
    "Mk_add_bilin_act = extract_Mk_from_logits(bilinear_add)\n",
    "Mk_add_relu_act  = extract_Mk_from_logits(relu_add)\n",
    "\n",
    "Mk_mul_bilin_w  = extract_Mk_bilinear_from_weights(bilinear_mul)\n",
    "Mk_mul_bilin_act = extract_Mk_from_logits(bilinear_mul)\n",
    "Mk_mul_relu_act  = extract_Mk_from_logits(relu_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 9. Fourier analysis (addition) – entropy per class\n",
    "# ============================================================\n",
    "\n",
    "def fourier_entropy(Mk):\n",
    "    \"\"\"\n",
    "    Mk: numpy array [MOD, MOD, MOD]  (a,b,k)\n",
    "    Returns: entropies H_k for each k.\n",
    "    \"\"\"\n",
    "    N = Mk.shape[0]\n",
    "    # DFT matrix F[u,a] = exp(-2πi * u*a / N) / sqrt(N)\n",
    "    n = np.arange(N)\n",
    "    omega = np.exp(-2j * np.pi / N)\n",
    "    F = omega ** np.outer(n, n) / np.sqrt(N)  # [N,N], complex\n",
    "\n",
    "    H = []\n",
    "    for k in range(N):\n",
    "        M = Mk[:, :, k]\n",
    "        M_hat = F @ M @ F.conj().T    # [N,N] complex\n",
    "        power = np.abs(M_hat) ** 2\n",
    "        power = power / power.sum()\n",
    "        p = power.flatten()\n",
    "        p = p[p > 0]                  # avoid log(0)\n",
    "        H_k = -np.sum(p * np.log(p))\n",
    "        H.append(H_k)\n",
    "    return np.array(H)\n",
    "\n",
    "# Compute entropies for addition\n",
    "H_add_bilin = fourier_entropy(Mk_add_bilin_w)\n",
    "H_add_relu  = fourier_entropy(Mk_add_relu_act)\n",
    "\n",
    "print(\"Mean entropy (add, bilinear):\", H_add_bilin.mean())\n",
    "print(\"Mean entropy (add, relu):    \", H_add_relu.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 10. Plot entropy histograms & example Fourier heatmaps\n",
    "# ============================================================\n",
    "\n",
    "# Histogram comparison\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(H_add_bilin, bins=20, alpha=0.5, label=\"Bilinear\")\n",
    "plt.hist(H_add_relu,  bins=20, alpha=0.5, label=\"ReLU\")\n",
    "plt.xlabel(\"Spectral entropy H_k\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Fourier entropy per class (addition)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Example Fourier heatmaps for a chosen class, say k=10\n",
    "k_example = 10\n",
    "N = MOD\n",
    "n = np.arange(N)\n",
    "omega = np.exp(-2j * np.pi / N)\n",
    "F = omega ** np.outer(n, n) / np.sqrt(N)\n",
    "\n",
    "def fourier_heat(Mk, k):\n",
    "    M = Mk[:, :, k]\n",
    "    M_hat = F @ M @ F.conj().T\n",
    "    return np.abs(M_hat)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(fourier_heat(Mk_add_bilin_w, k_example))\n",
    "plt.title(f\"Bilinear: |F M_{k_example} F*|\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(fourier_heat(Mk_add_relu_act, k_example))\n",
    "plt.title(f\"ReLU: |F M_{k_example} F*|\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 11. SVD / effective rank analysis (multiplication)\n",
    "# ============================================================\n",
    "\n",
    "def svd_effective_rank(Mk, thresh=0.9):\n",
    "    \"\"\"\n",
    "    Mk: [MOD,MOD,MOD]\n",
    "    Returns: r_k effective rank per class.\n",
    "    \"\"\"\n",
    "    N = Mk.shape[0]\n",
    "    ranks = []\n",
    "    for k in range(N):\n",
    "        M = Mk[:, :, k]\n",
    "        # SVD\n",
    "        u, s, vT = np.linalg.svd(M, full_matrices=False)\n",
    "        s2 = s ** 2\n",
    "        total = s2.sum()\n",
    "        cum = np.cumsum(s2)\n",
    "        r = np.searchsorted(cum, thresh * total) + 1\n",
    "        ranks.append(r)\n",
    "    return np.array(ranks)\n",
    "\n",
    "ranks_mul_bilin = svd_effective_rank(Mk_mul_bilin_w)\n",
    "ranks_mul_relu  = svd_effective_rank(Mk_mul_relu_act)\n",
    "\n",
    "print(\"Mean effective rank (mul, bilinear):\", ranks_mul_bilin.mean())\n",
    "print(\"Mean effective rank (mul, relu):    \", ranks_mul_relu.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 12. Plot rank histograms\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(ranks_mul_bilin, bins=20, alpha=0.5, label=\"Bilinear\")\n",
    "plt.hist(ranks_mul_relu,  bins=20, alpha=0.5, label=\"ReLU\")\n",
    "plt.xlabel(\"Effective rank r_k (90% energy)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Effective rank per class (multiplication)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 13. Ground-truth operator for addition and its entropy\n",
    "# ============================================================\n",
    "\n",
    "def true_Mk_add():\n",
    "    \"\"\"\n",
    "    Construct the exact modular addition operator as Mk[a,b,k],\n",
    "    with Mk[a,b,k] = 1 if k == (a+b mod MOD) else 0.\n",
    "    \"\"\"\n",
    "    Mk = np.zeros((MOD, MOD, MOD), dtype=np.float64)\n",
    "    for a in range(MOD):\n",
    "        for b in range(MOD):\n",
    "            k = (a + b) % MOD\n",
    "            Mk[a, b, k] = 1.0\n",
    "    return Mk\n",
    "\n",
    "Mk_true_add = true_Mk_add()\n",
    "H_true_add = fourier_entropy(Mk_true_add)\n",
    "\n",
    "print(\"Mean entropy (true addition):\", H_true_add.mean())\n",
    "print(\"Std  entropy (true addition):\", H_true_add.std())\n",
    "print(\"Mean entropy (add, bilinear):\", H_add_bilin.mean())\n",
    "print(\"Mean entropy (add, relu):    \", H_add_relu.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 14. Entropy histogram: true vs bilinear vs ReLU (addition)\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(H_true_add,  bins=20, alpha=0.5, label=\"True operator\")\n",
    "plt.hist(H_add_bilin, bins=20, alpha=0.5, label=\"Bilinear MLP\")\n",
    "plt.hist(H_add_relu,  bins=20, alpha=0.5, label=\"ReLU MLP\")\n",
    "plt.xlabel(\"Spectral entropy H_k\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Fourier entropy per class (addition mod 97)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 15. Check Mk from weights vs Mk from logits (bilinear, add)\n",
    "# ============================================================\n",
    "\n",
    "Mk_add_bilin_w   = extract_Mk_bilinear_from_weights(bilinear_add)\n",
    "Mk_add_bilin_act = extract_Mk_from_logits(bilinear_add)\n",
    "\n",
    "diff_mean = np.abs(Mk_add_bilin_w - Mk_add_bilin_act).mean()\n",
    "diff_max  = np.abs(Mk_add_bilin_w - Mk_add_bilin_act).max()\n",
    "print(\"Mean |Mk_w - Mk_act| (add, bilinear):\", diff_mean)\n",
    "print(\"Max  |Mk_w - Mk_act| (add, bilinear):\", diff_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 16. Centered SVD + stricter effective rank for multiplication\n",
    "# ============================================================\n",
    "\n",
    "def svd_effective_rank_centered(Mk, thresh=0.9):\n",
    "    \"\"\"\n",
    "    Center each M_k (remove row/col means) and compute effective rank.\n",
    "    \"\"\"\n",
    "    N = Mk.shape[0]\n",
    "    ranks = []\n",
    "    for k in range(N):\n",
    "        M = Mk[:, :, k].astype(np.float64)\n",
    "        # double-centering\n",
    "        M = M - M.mean(axis=0, keepdims=True)\n",
    "        M = M - M.mean(axis=1, keepdims=True)\n",
    "        M = M + M.mean()\n",
    "        u, s, vT = np.linalg.svd(M, full_matrices=False)\n",
    "        s2 = s**2\n",
    "        total = s2.sum()\n",
    "        cum = np.cumsum(s2)\n",
    "        r = np.searchsorted(cum, thresh * total) + 1\n",
    "        ranks.append(r)\n",
    "    return np.array(ranks)\n",
    "\n",
    "# Use logits-based Mk for both models for fairness\n",
    "Mk_mul_bilin = Mk_mul_bilin_act   # from logits\n",
    "Mk_mul_relu  = Mk_mul_relu_act    # from logits\n",
    "\n",
    "r_90_b = svd_effective_rank_centered(Mk_mul_bilin, thresh=0.9)\n",
    "r_99_b = svd_effective_rank_centered(Mk_mul_bilin, thresh=0.99)\n",
    "\n",
    "r_90_r = svd_effective_rank_centered(Mk_mul_relu, thresh=0.9)\n",
    "r_99_r = svd_effective_rank_centered(Mk_mul_relu, thresh=0.99)\n",
    "\n",
    "print(\"Centered eff rank (mul, bilinear) 90%:\", r_90_b.mean(), \"+/-\", r_90_b.std())\n",
    "print(\"Centered eff rank (mul, relu)     90%:\", r_90_r.mean(), \"+/-\", r_90_r.std())\n",
    "print(\"Centered eff rank (mul, bilinear) 99%:\", r_99_b.mean(), \"+/-\", r_99_b.std())\n",
    "print(\"Centered eff rank (mul, relu)     99%:\", r_99_r.mean(), \"+/-\", r_99_r.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 17. Rank histograms (centered) for multiplication\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.hist(r_99_b, bins=range(1, max(r_99_b.max(), r_99_r.max())+2), \n",
    "         alpha=0.5, label=\"Bilinear (99%)\", align=\"left\")\n",
    "plt.hist(r_99_r, bins=range(1, max(r_99_b.max(), r_99_r.max())+2),\n",
    "         alpha=0.5, label=\"ReLU (99%)\", align=\"left\")\n",
    "plt.xlabel(\"Effective rank r_k (99% energy, centered)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Effective rank per class (multiplication)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 18. Singular value decay plots for example classes (mul)\n",
    "# ============================================================\n",
    "\n",
    "def plot_sv_spectrum(Mk_bilin, Mk_relu, k_list=[0, 10, 20]):\n",
    "    for k in k_list:\n",
    "        M_b = Mk_bilin[:, :, k].astype(np.float64)\n",
    "        M_r = Mk_relu[:, :, k].astype(np.float64)\n",
    "\n",
    "        # (optionally) center as above\n",
    "        for label, M in [(\"Bilinear\", M_b), (\"ReLU\", M_r)]:\n",
    "            M_c = M - M.mean(axis=0, keepdims=True)\n",
    "            M_c = M_c - M_c.mean(axis=1, keepdims=True)\n",
    "            M_c = M_c + M_c.mean()\n",
    "\n",
    "            _, s, _ = np.linalg.svd(M_c, full_matrices=False)\n",
    "            s_norm = s / s[0]\n",
    "\n",
    "            plt.plot(s_norm, marker='o', label=f\"{label}, k={k}\")\n",
    "\n",
    "        plt.yscale(\"log\")\n",
    "        plt.xlabel(\"Singular value index\")\n",
    "        plt.ylabel(\"σ_i / σ_0 (log scale)\")\n",
    "        plt.title(f\"Singular value decay (multiplication, class k={k})\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "plot_sv_spectrum(Mk_mul_bilin, Mk_mul_relu, k_list=[0, 10, 20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
